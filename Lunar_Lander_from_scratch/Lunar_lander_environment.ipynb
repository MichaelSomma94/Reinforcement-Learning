{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f900b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import gym\n",
    "from gym.spaces import Box, Discrete\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gym\n",
    "from gym.spaces import Box, Discrete\n",
    "import random\n",
    "import copy\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "#from tqdm import tqdm\n",
    "from scipy.integrate import odeint\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a469a9",
   "metadata": {},
   "source": [
    "# Lunar Lander\n",
    "- this is an from scratch implementation of the lunar lander environment\n",
    "- it uses a numerical simulation for the environment based on scipy\n",
    "- the inhomogenous second order differential equation is solved using Runge-Kutta\n",
    "- every timestep is formulated by an initial value problem and the inhomogenous part is given by the applied action of the Reinforcement Learning agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lunar_Lander(gym.Env):\n",
    "    \n",
    "        #metadata = {'render.modes': ['human']}\n",
    "        def __init__(self):\n",
    "            super( Lunar_Lander, self).__init__()\n",
    "            self.action_space = Box(low=0, high=10000, shape= (2,)) #pass, make a cross at the first or second round\n",
    "            self.observation_space = Box(low=0, high=100000, shape= (9,))\n",
    "            self.state = np.array([2, 0, 20, 0, 0.1, 0, 5, 0, 0]) # x, x_dot, y, y_dot, alpha, alpha_dot, x_land, y_land, foot_l, foot_r\n",
    "            self.sim_state = np.array([2, 0, 20, 0, 0.1, 0])\n",
    "            self.current_step = 1\n",
    "            self.DT = np.array([0., 0.1])\n",
    "            self.lander = lander(4, 3, 1.936, 1, 1000)\n",
    "            self.center_mass_results = []\n",
    "            info = {}\n",
    "        def reset(self):\n",
    "            self.state = np.array([10-20*np.random.rand(), 1-2*np.random.rand(), 20-2*np.random.rand(), \n",
    "                                   0, 0.2-0.4*np.random.rand(), 0, 5, 0, 0]) # x, x_dot, y, y_dot, alpha, alpha_dot, x_land, y_land, foot_l, foot_r\n",
    "            self.sim_state = self.sim_state[0:6]\n",
    "            self.feet = self.lander.get_feet()\n",
    "            self.current_step = 1\n",
    "            self.DT = np.array([0., 0.1])\n",
    "            self.center_mass_results = []\n",
    "            return self.state\n",
    "        def step(self, action):\n",
    "            done = False\n",
    "            max_times_steps = 100\n",
    "            max_xvel = 0.5 # m/s\n",
    "            max_yvel = 0.5 # m/s\n",
    "            dt = 0.1 # sec \n",
    "            self.sim_state = self.state[0:6] # could do a function for that\n",
    "            feet = self.lander.get_feet()\n",
    "            feet = self.rot_trans(feet[0,:], feet[1,:])\n",
    "            \n",
    "            \n",
    "                #here comes a function that based on the sim state and the action \n",
    "            #print(action)\n",
    "            self.simulate_state(action)\n",
    "            self.state[0:6] = self.sim_state\n",
    "           \n",
    "            self.touch_down(np.array(feet))\n",
    "            \n",
    "            reward, done = self.feedback(max_times_steps, max_xvel, max_yvel)\n",
    "            \n",
    "            self.center_mass_results.append([self.state[0], self.state[2]])\n",
    "    \n",
    "            if self.current_step == max_times_steps: #after 1000 steps we stop this must be in accordance with the time in sim\n",
    "                done = True\n",
    "            self.current_step += 1\n",
    "            self.DT += dt\n",
    "            return self.state, reward, done, {}\n",
    "        \n",
    "        # the function that rotates and translate according to the center of mass motion \n",
    "        def rot_trans(self, x, y):\n",
    "            x_prime = []\n",
    "            y_prime = []\n",
    "            A = np.array([[np.cos(self.state[4]), -np.sin(self.state[4])],\n",
    "                  [np.sin(self.state[4]), np.cos(self.state[4])]])\n",
    "            for i in range(0,len(x)):\n",
    "                X = np.array([x[i], y[i]])\n",
    "                x_prime.append(np.matmul(A[0], X) + self.state[0]) \n",
    "                y_prime.append(np.matmul(A[1],X) + self.state[2])\n",
    "            x_prime = np.array(x_prime) \n",
    "            y_prime = np.array(y_prime)\n",
    "            return x_prime, y_prime\n",
    "        \n",
    "        def simulate_state(self, force):\n",
    "            state = odeint(lunar_lander, self.sim_state, self.DT, args=(force,))\n",
    "            self.sim_state = state[1,:]\n",
    "        \n",
    "        def touch_down(self, feet):\n",
    "            eps = 0.1 # toleranz for the touch down in m\n",
    "            if 0 < feet[1,0] < eps:\n",
    "                self.state[7] = 1\n",
    "            if 0 < feet[1,1] < eps:\n",
    "                self.state[8] = 1\n",
    "        \n",
    "        def feedback(self, max_times_steps, max_xvel, max_yvel):\n",
    "            reward = -(1 - (1 - self.current_step/(max_times_steps+1)))\n",
    "            done = False\n",
    "            if (self.state[6]-3 < self.state[0] < self.state[6]-3) and (bool(self.state[7]) and bool(self.state[8])):\n",
    "                  reward = 1\n",
    "                  done =True\n",
    "            if self.state[2] < 0:\n",
    "                reward = -1\n",
    "                done = True\n",
    "            if (bool(self.state[7]) or bool(self.state[8]) and abs(self.state[1])>max_xvel):\n",
    "                  reward = -1\n",
    "                  done = True\n",
    "            if (bool(self.state[7]) or bool(self.state[8]) and abs(self.state[3])>max_yvel):\n",
    "                  reward = -1\n",
    "                  done = True\n",
    "\n",
    "            return reward, done\n",
    "                \n",
    "        def render(self):\n",
    "            fig, ax = plt.subplots()\n",
    "            center_mass = np.array(self.center_mass_results)\n",
    "            ax.scatter(center_mass[:,0], center_mass[:,1] )\n",
    "            # the landing plaform and the lander body\n",
    "            lander_body_x, lander_body_y = self.rot_trans(self.lander.body[0, :], self.lander.body[1, :])\n",
    "            landing_platform = ax.scatter([self.state[6]+5, self.state[6]-5], [0,0])\n",
    "            ax.scatter(lander_body_x, lander_body_y)\n",
    "            ax.grid()\n",
    "            ax.axis('equal')\n",
    "            return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdc944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lunar_lander(state, t, force):\n",
    "   \n",
    "    g = -9.81 # m/s2\n",
    "    a = 4 #m\n",
    "    c = 3 #m\n",
    "    h = 1.936 #m\n",
    "    M = 10000 #kg\n",
    "    I = (a**2+h**2)*M/12\n",
    "\n",
    "    x = state[0] # is the angle\n",
    "    x_dot = state[1] # is the angular veloicity\n",
    "    dtx = x_dot\n",
    "    dtx_dot = (1/M)*(force[0]+force[1])*math.sin(state[4])\n",
    "    y = state[2] # is the angle\n",
    "    y_dot = state[3] # is the angular veloicity\n",
    "    dty = y_dot\n",
    "    dty_dot = (1/M)*(force[0]+force[1])*math.cos(state[4]) + g\n",
    "    alpha = state[4] # is the angle\n",
    "    alpha_dot = state[5] # is the angular veloicity\n",
    "    dtalpha = alpha_dot\n",
    "    dtalpha_dot = (1/I)*(-(a/2)*force[0]+(a/2)*force[1])\n",
    "    \n",
    "    dtstate_dt = [dtx, dtx_dot, dty, dty_dot, dtalpha, dtalpha_dot]\n",
    "    \n",
    "    return dtstate_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ccb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lander():\n",
    "    \n",
    "    def __init__(self, a, c, h, f, M):\n",
    "        self.a = a\n",
    "        self.c = c\n",
    "        self.h = h\n",
    "        self.foot = f\n",
    "        self.M = M\n",
    "        self.ys = h/3 * (a+2*c)/(a+c)\n",
    "        self.body = np.array([[-self.a/2, -self.a/2, -self.a/4, self.a/4, self.a/2, \n",
    "                               self.a/2, self.a/2 - (self.a/2-self.c/2)/2, self.c/2,\n",
    "                              0., -self.c/2, -(self.a/2 - (self.a/2-self.c/2)/2)],\n",
    "                              [-self.ys-self.foot, -self.ys, -self.ys, -self.ys, \n",
    "                               -self.ys,-self.ys-self.foot, self.h/2-self.ys, self.h-self.ys,\n",
    "                              self.h-self.ys, self.h-self.ys, self.h/2-self.ys]], \n",
    "                             dtype=object)\n",
    "        #self.I\n",
    "\n",
    "        # get the foot and body coordinate in the center of Mass system\n",
    "        #def body(self):\n",
    "        \n",
    "        \n",
    "    def render_it(self):\n",
    "         plt.scatter(self.body[0,:], self.body[1,:])\n",
    "    \n",
    "    def get_feet(self):\n",
    "        feet = np.array([[-self.a/2, self.a/2],[-self.ys-self.foot, -self.ys-self.foot]])\n",
    "        return feet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b0d06",
   "metadata": {},
   "source": [
    "- this is a random agent to check if the environment is working as it is supposed to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55b259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lunar = Lunar_Lander()\n",
    "test_lunar.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = test_lunar.action_space.sample()\n",
    "    state, reward, done, _ = test_lunar.step(action)\n",
    "    print(reward, done)\n",
    "test_lunar.render()\n",
    "#test_lunar.action_space.sample()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
